\chapter{Introduction}
\label{cha:Introduction}

In todays world, more and more technologies based on Machine Learning are present within everyday life. Those grow in their applicability and already span numerous fields. Knowingly ML technologies are also used in the image domain, where they show the ability to alter but also generate pictures. Prominently image style transfer, is one of those, applying neural networks to extract and combine characteristics of two pictures to synthesize a new one. This leads to the idea to also apply ML technologies such as neural networks in the audio domain to synthesize novel sounds. The basic idea behind this topic is to take two instruments as a source, and generate one sound based on the characteristics of both instruments. For example to use a guitar signal and combine it with the characteristics of e.g. a synthesizer to form a novel output sound. By using technologies such as convolutional neural networks, combined with the knowledge of the image domain, this should enable the generation of interesting sounds in a new way. Therefore this topic is of high interest, as through it new ways of generating music can be explored. 

This thesis therefore aims to explore the capabilities of convolutional neural networks to be used for the task of audio synthesis. As the emphasis in this work lies on using convolutional neural networks, the input audio data is provided as spectrograms. Like in some works that are discussed in chapter \ref{cha:related_works}, through all experiments, this work applies a neural network shaped as an autoencoder, which has the feature of projecting the input data on a lower dimensional space, in the first part of the network. From this representation, which is also called embedding, the second part also called decoder, tries to reconstruct the input data from it. By introducing a step that interpolates the compressed data of two different input samples, a new embedding gets generated. The decoder part in addition generates a spectrogram containing characteristics of both input samples, which then gets converted back into time-domain resulting in a new synthesized sound. Finally through this technique it should be possible to generate interesting novel sounds based on different combinations of two audio samples.

\newpage
\section{Research questions}
For this work some research questions have been defined that are answered by the evaluation of the conducted experiments, described throughout this thesis. The main goal of this thesis is to prove whether it is possible to create novel sounds, based on the characteristics of two instruments by using ML technologies such as convolutional neural networks. Furthermore it should be evaluated based on different neural network configurations, how those influence the quality of the output but also the models performance. As the pre-processing takes an important part in a ML-toolchain it will be shown how this also influences the model performance itself but also the quality of the synthesized sounds. Because the neural network extracts features of the input that are used for the synthesis, this work also gives an insight on what information the neural network learns. Finally as spectrograms are used as the input source for the models, a short evaluation shows if those are suited best for the task of neural audio synthesis.

\section{Outline of the thesis}
This section gives a short overview on the different chapters as well as a short explanation on what to expect in each.
While this first chapter gives an introduction to this work, the following chapter \ref{cha:related_works} discusses already existing approaches around generating audio with neural networks. Specifically works concerning neural audio synthesis but also audio style transfer, get discussed as those approaches have a high relevance for this thesis. Chapter \ref{cha:Approach} explains the general methodology and applied technologies, to get a detailed look on how this work achieves the task of neural audio synthesis. Based on this methodology, in chapter \ref{cha:Experiment} the conducted experiments will be described as those serve to derive the answers to the previously stated research questions. The succeeding chapter \ref{cha:Results} depicts the results that were obtained by carrying out the stated experiments. These results incorporate visual representations of the output such as spectrograms and embeddings but also numbers showing the models error scores. Chapter \ref{cha:Discussion} discusses the results in combination with an auditory evaluation of the output generated by the neural networks, and delivers the findings to answer the research questions. In the last chapter \ref{cha:Conclusion} the research questions will be answered by the findings obtained in the discussion. There also a future outlook is contained, that provides possible further research points to be carried out in the future.