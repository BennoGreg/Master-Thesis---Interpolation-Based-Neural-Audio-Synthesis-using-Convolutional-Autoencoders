\chapter{Kurzfassung}

\begin{german}
In der heutigen Welt, gewinnen Machine Learning Technologien immer mehr an Präsenz im Alltag. Während diese Technologien für die Erleichterung alltäglicher Aufgaben eingesetzt werden, gewinnen sie immer mehr an Bedeutung für die Nutzung in der Unterhaltung inklusive im Audio Bereich. Nicht zuletzt um mit ihnen Klänge oder auch Musik zu generieren. 

Da dieses Themengebiet von hohem Interesse zeugt, beschäftigt sich diese Masterarbeit mit der Erforschung der Anwendbarkeit von Machine Learning Techniken wie neuronaler Netzwerke um neuartige Klänge zu erzeugen. Da in diesem Bereich bereits Ansätze existieren, fokussiert sich diese Arbeit auf die Benützung von Convolutional Autoencoder Netzwerken. Im Zuge dieser Arbeit werden Experimente durchgeführt welche die Eignung von Convolutional Autoencodern untersuchen, die sich hinsichtlich der angewandten Art von Convolution (1D oder 2D) bzw. auch dem angewandten Stride unterscheiden. Da diese Experimente mit log-magnitude Spektrogrammen durchgeführt werden, gibt es zum Vergleich noch zusätzliche Experimente mit log-mel Spektrogrammen. Diese Autoencoder Netzwerke sind darauf trainiert, Spektrogramme zu rekonstruieren. Durch das Einbringen Interpolierungsschrittes der Werte von zwei Audio-Samples in der kleinsten Netzwerkschicht, konstruiert das Netzwerk ein neuartiges Spektrogram. Durch die Transformation dieses Spektrogramms in den Zeitbereich, resultiert daraus ein neuartiger Sound welcher die Charakteristiken von zwei Audio-Samples beinhaltet. Während hauptsächlich die Eignung von Convolutional Autoencodern zur Klangerzeugung erforscht wird, zeigen diese Experimente auch, welche Netzwerkkonfiguration bzw. Art von Spektrogrammen am besten geeignet sind. Dies erfolgt mit Hinsicht auf die Model-Performance aber vor allem auch die Qualität des Outputs.

Durch die durchgeführten Experimente und deren Ergebnisse in dieser Masterarbeit, konnte beobachtet werden, dass unterschiedliche Konfigurationen der Netzwerke die Performance des Models sowie auch die Qualität vom Ergebnis wesentlich beeinflussen. Erwähnenswert hier vor allem, die Netzwerke mit 2D Convolutions und niedrigem Stride, da diese am besten punkto auditiver Qualität abgeschnitten haben. Andererseits durch zu hohem Stride bzw. Verwendung von 1D Convolutions verringerte sich die auditive Qualität signifikant. Dies konnte auch bei der Verwendung von log-mel Spektrogrammen im Kontrast zu log-magnitude Spektrogrammen beobachtet werden. Diese Erkenntnisse konnten einerseits durch das Rekonstruieren von einzelnen Spektrogrammen aber auch mit angewandten Interpolierung in der kleinsten Netzwerkschicht, bestätigt werden. Als Ergebnis dieser Arbeit wurde nichtdestotrotz bewiesen, dass man mithilfe von Convolutional Autoencodern, neuartige Sounds generieren kann, die auf den Charakteristiken von zwei Audio-Samples basieren.

\end{german}